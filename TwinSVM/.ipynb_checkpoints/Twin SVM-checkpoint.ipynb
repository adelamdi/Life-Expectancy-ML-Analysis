{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14f6f87-fb00-45c4-b5a8-9cf591fff3a9",
   "metadata": {},
   "source": [
    "### Twin SVM using Python\n",
    "#### Author: Adel Ahmadi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4810f9e6-e69c-431e-8736-cdd76abb112a",
   "metadata": {},
   "source": [
    "Lets import libraries at first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30051a5-72ad-4d79-8b12-1b579683905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b1033b-b659-442a-a7ef-5aa3885df6a6",
   "metadata": {},
   "source": [
    "Lets load our dataset and create X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73cc07de-a28d-4488-b585-a821583057f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n"
     ]
    }
   ],
   "source": [
    "# Loading Dataset\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"paperxd/cleaned-life-expectancy-dataset\")\n",
    "filename = path + '/Cleaned-Life-Exp.csv'\n",
    "data = pd.read_csv(filename)\n",
    "data = data.drop(columns=['Country'])\n",
    "\n",
    "# Creating X\n",
    "X = data.drop(columns=['Status'])\n",
    "\n",
    "# Convert labels to +-1 and Creating Y\n",
    "# Binning countinues life expectancy\n",
    "bins = [-4,-1.5,0.5,3]\n",
    "labels = ['Low','Medium','High']\n",
    "data['lifeexp_category'] = pd.cut(data['Life expectancy'], bins = bins, labels = labels)\n",
    "y = data['lifeexp_category']\n",
    "y = np.where(y == 'High', 1, -1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e0ddf-5a8c-4bcf-a0be-6bf014b51bcd",
   "metadata": {},
   "source": [
    "We create a class named TwinSVM for fitting the model without any extra libraries. also we have a predict function for predicting new datas with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45291dcc-49af-464f-84fc-53e1292d5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwinSVM:\n",
    "    def __init__(self, penalty=1.0):\n",
    "        self.penalty = penalty  \n",
    "\n",
    "    def fit(self, data, labels):\n",
    "        group1 = data[labels == 1]\n",
    "        group2 = data[labels == -1]\n",
    "        \n",
    "        # Adding bias term to each group\n",
    "        augmented1 = np.hstack((group1, np.ones((group1.shape[0], 1))))\n",
    "        augmented2 = np.hstack((group2, np.ones((group2.shape[0], 1))))\n",
    "        \n",
    "        # First plane's calculation\n",
    "        A1 = np.dot(augmented1.T, augmented1) + self.penalty * np.identity(augmented1.shape[1])\n",
    "        b1 = -np.dot(augmented2.T, np.ones(augmented2.shape[0]))\n",
    "        self.hyperplane1 = np.linalg.solve(A1, b1)\n",
    "        \n",
    "        # Second plane's calculation\n",
    "        A2 = np.dot(augmented2.T, augmented2) + self.penalty * np.identity(augmented2.shape[1])\n",
    "        b2 = -np.dot(augmented1.T, np.ones(augmented1.shape[0]))\n",
    "        self.hyperplane2 = np.linalg.solve(A2, b2)\n",
    "\n",
    "    def predict(self, data):\n",
    "        d1 = np.dot(data, self.hyperplane1[:-1]) + self.hyperplane1[-1]\n",
    "        d2 = np.dot(data, self.hyperplane2[:-1]) + self.hyperplane2[-1]\n",
    "        \n",
    "        # Choose class based on closest distance\n",
    "        return np.where(np.abs(d1) < np.abs(d2), 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13140100-7467-4c99-8521-2884bf70d7da",
   "metadata": {},
   "source": [
    "Lets train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc3a501-70ec-4f01-bc57-01d271ccae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "model = TwinSVM()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbdea3-1832-43ac-a802-553410280d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
