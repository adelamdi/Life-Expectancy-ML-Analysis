{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1cbef1-6819-47d5-bd7b-ea9f8e9d90ed",
   "metadata": {},
   "source": [
    "### Feature Selection With GA\n",
    "#### Adel Ahmadi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d0710-3141-441a-8559-b9dc4957ddeb",
   "metadata": {},
   "source": [
    "##### In this step, we try to use Genetic algorithm for feature selection. first, lets load data and our most accurate model from previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4591cf94-99cb-48e2-9c43-15f01d44ce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (0.3.1)\n",
      "Requirement already satisfied: packaging in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from kagglehub) (23.1)\n",
      "Requirement already satisfied: requests in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from kagglehub) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99178b6-1816-483e-99a5-85f05dea378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Path to dataset files: /Users/adelahmadi/.cache/kagglehub/datasets/paperxd/cleaned-life-expectancy-dataset/versions/1\n",
      "File name: Cleaned-Life-Exp.csv\n"
     ]
    }
   ],
   "source": [
    "# Loading Dataset\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"paperxd/cleaned-life-expectancy-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "print(\"File name: Cleaned-Life-Exp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f6142f-8829-4af9-8c50-833930737980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.93      0.92      0.93       317\n",
      "         Low       0.84      0.71      0.77        86\n",
      "      Medium       0.90      0.93      0.91       479\n",
      "\n",
      "    accuracy                           0.91       882\n",
      "   macro avg       0.89      0.85      0.87       882\n",
      "weighted avg       0.91      0.91      0.90       882\n",
      "\n",
      "SVM Accuracy: 0.9058956916099773\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "filename = path + '/Cleaned-Life-Exp.csv'\n",
    "filename\n",
    "data = pd.read_csv(filename)\n",
    "# Binning countinues life expectancy\n",
    "bins = [-4,-1.5,0.5,3]\n",
    "labels = ['Low','Medium','High']\n",
    "data['lifeexp_category'] = pd.cut(data['Life expectancy'], bins = bins, labels = labels)\n",
    "X = data.drop(['Life expectancy','lifeexp_category'],axis=1)\n",
    "column_names = data.columns\n",
    "X = pd.get_dummies(X, columns=['Country'], drop_first=True)\n",
    "Y = data['lifeexp_category']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X,Y,test_size = .3, random_state = 20)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "scaler = StandardScaler()\n",
    "X_Train_Scaled = scaler.fit_transform(X_Train)\n",
    "X_Test_Scaled = scaler.transform(X_Test)\n",
    "model = SVC(kernel='rbf', C=100, gamma=0.1)\n",
    "model.fit(X_Train_Scaled, Y_Train)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_predicted = model.predict(X_Test_Scaled)\n",
    "print(classification_report(Y_Test, y_predicted))\n",
    "svm_accuracy = accuracy_score(Y_Test, y_predicted)\n",
    "print('SVM Accuracy:',svm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556987b-6f7e-45af-a12f-3d6a87b5722c",
   "metadata": {},
   "source": [
    "Lets move on to feature selection with GA. First, we install sklearn-genetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6970db9b-7e28-494f-9668-b1c2541aec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-genetic in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from sklearn-genetic) (1.2.2)\n",
      "Requirement already satisfied: deap>=1.0.2 in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from sklearn-genetic) (1.4.1)\n",
      "Requirement already satisfied: numpy in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from sklearn-genetic) (1.26.4)\n",
      "Requirement already satisfied: multiprocess in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from sklearn-genetic) (0.70.17)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.0->sklearn-genetic) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.0->sklearn-genetic) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.0->sklearn-genetic) (2.2.0)\n",
      "Requirement already satisfied: dill>=0.3.9 in /Users/adelahmadi/Documents/Anaconda/anaconda3/lib/python3.11/site-packages (from multiprocess->sklearn-genetic) (0.3.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn-genetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08fdc2ee-2d84-4fad-b4a7-85e33c8e07c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                         \tmax                            \n",
      "0  \t50    \t[ 0.723437  3.3       0.01922 ]\t[ 0.075845  1.431782  0.006754]\t[ 0.52189  1.       0.00362]\t[ 0.854069  5.        0.033821]\n",
      "1  \t22    \t[-799.280717    4.2       800.016881]\t[ 2713.144099     1.113553  2712.927015]\t[-10000.            2.            0.006649]\t[     0.854069      7.        10000.      ]\n",
      "2  \t29    \t[-1199.276857     4.54      1200.018474]\t[ 3249.8824       1.023914  3249.60854 ]\t[-10000.            2.            0.004701]\t[     0.860389      7.        10000.      ]\n",
      "3  \t31    \t[-1199.259155     4.56      1200.019209]\t[ 3249.888937     0.983056  3249.608268]\t[-10000.            3.            0.004701]\t[     0.860876      7.        10000.      ]\n",
      "4  \t23    \t[-799.214771    4.22      800.021957]   \t[ 2713.163545     0.756042  2712.925519]\t[-10000.            2.            0.012606]\t[     0.86672      6.       10000.     ]   \n",
      "5  \t21    \t[-199.160045    4.22      200.023249]   \t[ 1400.119994     0.641561  1399.996679]\t[-10000.            3.            0.011446]\t[     0.871099      6.        10000.      ]\n",
      "6  \t30    \t[-999.223458    4.48     1000.021853]   \t[ 3000.258847     0.921737  2999.992716]\t[-10000.            3.            0.013492]\t[     0.879364      7.        10000.      ]\n",
      "7  \t34    \t[-599.188156    4.56      600.021508]   \t[ 2375.073526     0.80399   2374.862984]\t[-10000.            3.            0.011507]\t[     0.879364      7.        10000.      ]\n",
      "8  \t36    \t[-599.184614    4.78      600.019429]   \t[ 2375.074421     0.575847  2374.863509]\t[-10000.            3.            0.013492]\t[     0.879364      6.        10000.      ]\n",
      "9  \t32    \t[-1399.250682     5.        1400.014938]\t[ 3470.172645     0.69282   3469.864287]\t[-10000.            4.            0.012746]\t[     0.879364      8.        10000.      ]\n",
      "10 \t32    \t[-1199.23113      5.        1200.014906]\t[ 3249.899286     0.52915   3249.609857]\t[-10000.            3.            0.011636]\t[     0.879364      6.        10000.      ]\n",
      "11 \t32    \t[-199.138574    5.        200.016869]   \t[ 1400.123061     0.2       1399.99759 ]\t[-10000.            4.            0.012746]\t[     0.879364      6.        10000.      ]\n",
      "12 \t30    \t[-999.211705    5.02     1000.015961]   \t[ 3000.262765     0.423792  2999.99468 ]\t[-10000.            4.            0.012746]\t[     0.879364      6.        10000.      ]\n",
      "13 \t20    \t[-799.191734    5.1       800.015933]   \t[ 2713.170338     0.458258  2712.927295]\t[-10000.            4.            0.014226]\t[     0.879364      7.        10000.      ]\n",
      "14 \t31    \t[-1199.229729     5.06      1200.014997]\t[ 3249.899803     0.42      3249.609824]\t[-10000.            4.            0.009884]\t[     0.880828      6.        10000.      ]\n",
      "15 \t32    \t[-1199.226286     5.12      1200.015149]\t[ 3249.901075     0.430813  3249.609768]\t[-10000.            4.            0.012746]\t[     0.880828      7.        10000.      ]\n",
      "16 \t29    \t[-799.191082    5.1       800.015814]   \t[ 2713.17053      0.458258  2712.92733 ]\t[-10000.            4.            0.012746]\t[     0.880828      7.        10000.      ]\n",
      "17 \t27    \t[-599.174769    5.06      600.016204]   \t[ 2375.076908     0.237487  2374.864323]\t[-10000.            5.            0.006599]\t[     0.880828      6.        10000.      ]\n",
      "18 \t32    \t[-1399.244087     5.1       1400.014833]\t[ 3470.175305     0.412311  3469.86433 ]\t[-10000.            4.            0.015822]\t[     0.880828      6.        10000.      ]\n",
      "19 \t34    \t[-799.193084    5.04      800.015527]   \t[ 2713.16994      0.397995  2712.927414]\t[-10000.            3.            0.015897]\t[     0.880828      6.        10000.      ]\n",
      "20 \t27    \t[-799.191886    5.08      800.015085]   \t[ 2713.170293     0.523068  2712.927545]\t[-10000.            4.            0.012676]\t[     0.880828      8.        10000.      ]\n",
      "21 \t21    \t[-1399.243908     5.14      1400.013649]\t[ 3470.175378     0.447661  3469.864808]\t[-10000.            4.            0.013002]\t[     0.880828      7.        10000.      ]\n",
      "22 \t21    \t[-999.207255    5.16     1000.014307]   \t[ 3000.264248     0.504381  2999.995231]\t[-10000.            5.            0.015897]\t[     0.880828      7.        10000.      ]\n",
      "23 \t32    \t[-799.190124    5.08      800.014542]   \t[ 2713.170813     0.391918  2712.927705]\t[-10000.            4.            0.011804]\t[     0.880828      7.        10000.      ]\n",
      "24 \t17    \t[-599.174045    5.        600.015091]   \t[ 2375.077091     0.34641   2374.864605]\t[-10000.            4.            0.013002]\t[     0.880828      6.        10000.      ]\n",
      "25 \t17    \t[-799.190309    5.08      800.014704]   \t[ 2713.170758     0.271293  2712.927657]\t[-10000.            5.            0.015897]\t[     0.880828      6.        10000.      ]\n",
      "26 \t30    \t[-1399.242488     5.22      1400.013671]\t[ 3470.175951     0.575847  3469.864799]\t[-10000.            5.            0.015897]\t[     0.880828      7.        10000.      ]\n",
      "27 \t23    \t[-199.136788    5.04      200.015579]   \t[ 1400.123316     0.28      1399.997774]\t[-10000.            5.            0.015897]\t[     0.880828      7.        10000.      ]\n",
      "28 \t24    \t[-1799.277721     5.26      1800.013035]\t[ 3842.212946     0.626418  3841.868435]\t[-10000.            5.            0.015897]\t[     0.880828      8.        10000.      ]\n",
      "29 \t34    \t[-799.189638    5.14      800.014625]   \t[ 2713.170956     0.529528  2712.927681]\t[-10000.            5.            0.015897]\t[     0.880828      8.        10000.      ]\n",
      "30 \t24    \t[-1199.226116     5.14      1200.014075]\t[ 3249.901137     0.490306  3249.610164]\t[-10000.            4.            0.015897]\t[     0.880828      7.        10000.      ]\n",
      "31 \t31    \t[-599.172021    5.06      600.014943]   \t[ 2375.077603     0.237487  2374.864642]\t[-10000.            5.            0.015897]\t[     0.880828      6.        10000.      ]\n",
      "32 \t26    \t[-799.189638    5.1       800.014625]   \t[ 2713.170956     0.360555  2712.927681]\t[-10000.            5.            0.015897]\t[     0.880828      7.        10000.      ]\n",
      "33 \t29    \t[-999.208149    5.12     1000.014128]   \t[ 3000.26395      0.620967  2999.995291]\t[-10000.            4.            0.012746]\t[     0.880828      7.        10000.      ]\n",
      "34 \t25    \t[-599.172362    5.04      600.014885]   \t[ 2375.077517     0.28      2374.864657]\t[-10000.            4.            0.013002]\t[     0.880828      6.        10000.      ]\n",
      "35 \t29    \t[-799.189638    5.14      800.014625]   \t[ 2713.170956     0.529528  2712.927681]\t[-10000.            5.            0.015897]\t[     0.880828      8.        10000.      ]\n",
      "36 \t24    \t[-1199.226612     5.1       1200.013995]\t[ 3249.900954     0.458258  3249.610194]\t[-10000.            4.            0.008958]\t[     0.880828      7.        10000.      ]\n",
      "37 \t22    \t[-199.140825    5.04      200.01574 ]   \t[ 1400.122739     0.631189  1399.997752]\t[-10000.            3.            0.011642]\t[     0.880828      9.        10000.      ]\n",
      "38 \t28    \t[-799.191301    5.08      800.014606]   \t[ 2713.170466     0.523068  2712.927686]\t[-10000.            4.            0.008958]\t[     0.880828      8.        10000.      ]\n",
      "39 \t29    \t[-599.173587    5.04      600.014746]   \t[ 2375.077207     0.397995  2374.864692]\t[-10000.            4.            0.008958]\t[     0.880828      7.        10000.      ]\n",
      "40 \t24    \t[-799.190611    5.1       800.014475]   \t[ 2713.170669     0.360555  2712.927725]\t[-10000.            5.            0.008417]\t[     0.880828      7.        10000.      ]\n",
      "41 \t22    \t[-399.157576    5.04      400.015295]   \t[ 1959.763753     0.488262  1959.588672]\t[-10000.            4.            0.012746]\t[     0.880828      8.        10000.      ]\n",
      "42 \t37    \t[-799.191622    5.06      800.014461]   \t[ 2713.170371     0.42      2712.927729]\t[-10000.            4.            0.011804]\t[     0.880828      7.        10000.      ]\n",
      "43 \t30    \t[-599.175358    5.04      600.015026]   \t[ 2375.07676      0.445421  2374.864621]\t[-10000.            3.            0.015897]\t[     0.880828      7.        10000.      ]\n",
      "44 \t40    \t[-399.157381    5.        400.01507 ]   \t[ 1959.763793     0.282843  1959.588718]\t[-10000.            4.            0.008958]\t[     0.880828      6.        10000.      ]\n",
      "45 \t22    \t[-599.172236    5.06      600.01488 ]   \t[ 2375.077548     0.369324  2374.864658]\t[-10000.            4.            0.012746]\t[     0.880828      7.        10000.      ]\n",
      "46 \t27    \t[-1199.226437     5.12      1200.013792]\t[ 3249.901019     0.515364  3249.610269]\t[-10000.            4.            0.008958]\t[     0.880828      7.        10000.      ]\n",
      "47 \t29    \t[-1399.245669     5.18      1400.013861]\t[ 3470.174667     0.589576  3469.864722]\t[-10000.            4.            0.015897]\t[     0.880828      8.        10000.      ]\n",
      "48 \t31    \t[-1199.226087     5.18      1200.013832]\t[ 3249.901148     0.554617  3249.610254]\t[-10000.            5.            0.008034]\t[     0.880828      8.        10000.      ]\n",
      "49 \t22    \t[-199.140835    4.96      200.015743]   \t[ 1400.122738     0.397995  1399.997751]\t[-10000.            4.            0.008958]\t[     0.880828      7.        10000.      ]\n",
      "50 \t34    \t[-1399.243042     5.14      1400.01355 ]\t[ 3470.175727     0.529528  3469.864847]\t[-10000.            4.            0.012746]\t[     0.880828      7.        10000.      ]\n",
      "Selected Features Recommended by GA: Index(['Adult Mortality', 'Alcohol', 'Income composition of resources', 'Year',\n",
      "       'thinness  1-19 years'],\n",
      "      dtype='object')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.90      0.86      0.88       317\n",
      "         Low       0.84      0.80      0.82        86\n",
      "      Medium       0.88      0.91      0.89       479\n",
      "\n",
      "    accuracy                           0.88       882\n",
      "   macro avg       0.87      0.86      0.87       882\n",
      "weighted avg       0.88      0.88      0.88       882\n",
      "\n",
      "SVM Model Accuracy After GA Feature Selection: 0.8832199546485261\n"
     ]
    }
   ],
   "source": [
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# List of columns you want to run GA for (adjust this based on your specific columns)\n",
    "selected_columns = data.columns.difference(['Life expectancy', 'lifeexp_category','Country']) \n",
    "\n",
    "# SVM model\n",
    "model = SVC(kernel='rbf', C=100, gamma=0.1)\n",
    "\n",
    "# Filter the dataset to include only the selected columns\n",
    "X_Train_Selected_Columns = X_Train[selected_columns]\n",
    "X_Test_Selected_Columns = X_Test[selected_columns]\n",
    "\n",
    "# Genetic Algorithm for Feature Selection on the selected columns\n",
    "ga_selector = GeneticSelectionCV(\n",
    "    estimator=model,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    scoring=\"accuracy\",\n",
    "    max_features=min(5, X_Train_Selected_Columns.shape[1]),  # Limiting max features\n",
    "    n_population=50,  # Number of individuals in the population\n",
    "    n_generations=50,  # Number of generations\n",
    "    crossover_proba=0.5,  # Probability of crossover\n",
    "    mutation_proba=0.2,  # Probability of mutation\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GA selector on the selected columns\n",
    "ga_selector = ga_selector.fit(X_Train_Selected_Columns, Y_Train)\n",
    "\n",
    "# After GA feature selection, use the selected features (columns) from the filtered dataset\n",
    "selected_features = X_Train_Selected_Columns.columns[ga_selector.support_]\n",
    "print(\"Selected Features Recommended by GA:\", selected_features)\n",
    "\n",
    "# Select the columns based on the selected features\n",
    "X_Train_Selected = X_Train_Selected_Columns[selected_features]\n",
    "X_Test_Selected = X_Test_Selected_Columns[selected_features]\n",
    "\n",
    "# Scale the selected features\n",
    "X_Train_Selected_Scaled = scaler.fit_transform(X_Train_Selected)\n",
    "X_Test_Selected_Scaled = scaler.transform(X_Test_Selected)\n",
    "\n",
    "# Train SVM on the selected features\n",
    "model.fit(X_Train_Selected_Scaled, Y_Train)\n",
    "y_predicted_ga = model.predict(X_Test_Selected_Scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(Y_Test, y_predicted_ga))\n",
    "svm_ga_accuracy = accuracy_score(Y_Test, y_predicted_ga)\n",
    "print(\"SVM Model Accuracy After GA Feature Selection:\", svm_ga_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
